{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5be58427-a880-4f1d-b077-78af01d95862",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "\n",
    "import kenlm\n",
    "import torch\n",
    "import torchaudio\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC\n",
    "\n",
    "\n",
    "class Wav2Vec2Decoder:\n",
    "    def __init__(\n",
    "            self,\n",
    "            model_name=\"facebook/wav2vec2-base-960h\",\n",
    "            lm_model_path=\"lm/3-gram.pruned.1e-7.arpa.gz\",\n",
    "            beam_width=3,\n",
    "            alpha=1.0,\n",
    "            beta=1.0\n",
    "        ):\n",
    "        \"\"\"\n",
    "        Initialization of Wav2Vec2Decoder class\n",
    "        \n",
    "        Args:\n",
    "            model_name (str): Pretrained Wav2Vec2 model from transformers\n",
    "            lm_model_path (str): Path to the KenLM n-gram model (for LM rescoring)\n",
    "            beam_width (int): Number of hypotheses to keep in beam search\n",
    "            alpha (float): LM weight for shallow fusion and rescoring\n",
    "            beta (float): Word bonus for shallow fusion\n",
    "        \"\"\"\n",
    "        # once logits are available, no other interactions with the model are allowed\n",
    "        self.processor = Wav2Vec2Processor.from_pretrained(model_name)\n",
    "        self.model = Wav2Vec2ForCTC.from_pretrained(model_name)\n",
    "\n",
    "        # you can interact with these parameters\n",
    "        self.vocab = {i: c for c, i in self.processor.tokenizer.get_vocab().items()}\n",
    "        self.blank_token_id = self.processor.tokenizer.pad_token_id\n",
    "        self.word_delimiter = self.processor.tokenizer.word_delimiter_token\n",
    "        self.beam_width = beam_width\n",
    "        self.alpha = 0.05\n",
    "        self.beta = 0.0\n",
    "        self.lm_model = kenlm.Model(lm_model_path) if lm_model_path else None\n",
    "\n",
    "    def greedy_decode(self, logits: torch.Tensor) -> str:\n",
    "        \"\"\"\n",
    "        Perform greedy decoding (find best CTC path)\n",
    "        \n",
    "        Args:\n",
    "            logits (torch.Tensor): Logits from Wav2Vec2 model (T, V)\n",
    "        \n",
    "        Returns:\n",
    "            str: Decoded transcript\n",
    "        \"\"\"\n",
    "        predictions = torch.argmax(logits, dim=-1).tolist()\n",
    "        result = []\n",
    "        previous_token = None\n",
    "        for token in predictions:\n",
    "            if token == self.blank_token_id:\n",
    "                previous_token = token\n",
    "                continue\n",
    "            if token == previous_token:\n",
    "                continue\n",
    "            result.append(self.vocab[token])\n",
    "            previous_token = token\n",
    "        transcript = ''.join(result).replace(self.word_delimiter, ' ')\n",
    "        return transcript\n",
    "\n",
    "    def beam_search_decode(self, logits: torch.Tensor, return_beams: bool = False):\n",
    "        \"\"\"\n",
    "        Perform beam search decoding (no LM)\n",
    "        \n",
    "        Args:\n",
    "            logits (torch.Tensor): Logits from Wav2Vec2 model (T, V), where\n",
    "                T - number of time steps and\n",
    "                V - vocabulary size\n",
    "            return_beams (bool): Return all beam hypotheses for second pass LM rescoring\n",
    "        \n",
    "        Returns:\n",
    "            Union[str, List[Tuple[float, List[int]]]]: \n",
    "                (str) - If return_beams is False, returns the best decoded transcript as a string.\n",
    "                (List[Tuple[List[int], float]]) - If return_beams is True, returns a list of tuples\n",
    "                    containing hypotheses and log probabilities.\n",
    "        \"\"\"\n",
    "        log_probs = torch.log_softmax(logits, dim=-1)\n",
    "        current_beam = {(): 0.0}\n",
    "        for t in range(log_probs.shape[0]):\n",
    "            new_beam = {}\n",
    "            for hypothesis, score in current_beam.items():\n",
    "                blank_score = score + log_probs[t, self.blank_token_id].item()   \n",
    "                if hypothesis in new_beam:\n",
    "                    new_beam[hypothesis] = max(new_beam[hypothesis], blank_score)\n",
    "                else:\n",
    "                    new_beam[hypothesis] = blank_score\n",
    "                for token_id in range(log_probs.shape[1]):\n",
    "                    if token_id == self.blank_token_id:\n",
    "                        continue            \n",
    "                    token_score = log_probs[t, token_id].item()\n",
    "                    if len(hypothesis) > 0 and token_id == hypothesis[-1]:\n",
    "                        if hypothesis in new_beam:\n",
    "                            new_beam[hypothesis] = max(new_beam[hypothesis], score + token_score)\n",
    "                        else:\n",
    "                            new_beam[hypothesis] = score + token_score\n",
    "                    new_hypothesis = hypothesis + (token_id,)\n",
    "                    new_hypothesis_score = score + token_score        \n",
    "                    if new_hypothesis in new_beam:\n",
    "                        new_beam[new_hypothesis] = max(new_beam[new_hypothesis], new_hypothesis_score)\n",
    "                    else:\n",
    "                        new_beam[new_hypothesis] = new_hypothesis_score\n",
    "            sorted_beam = sorted(new_beam.items(), key=lambda x: x[1], reverse=True)\n",
    "            current_beam = dict(sorted_beam[:self.beam_width])\n",
    "        beams = [(list(hyp), score) for hyp, score in current_beam.items()]\n",
    "        if return_beams:\n",
    "            return beams\n",
    "        else:\n",
    "            best_hypothesis = \"\"\n",
    "            if beams:\n",
    "                best_tokens = beams[0][0]\n",
    "                best_hypothesis = ''.join([self.vocab[token] for token in best_tokens])\n",
    "                best_hypothesis = best_hypothesis.replace(self.word_delimiter, ' ')\n",
    "            return best_hypothesis\n",
    "\n",
    "    def beam_search_with_lm(self, logits: torch.Tensor) -> str:\n",
    "        \"\"\"\n",
    "        Perform beam search decoding with shallow LM fusion\n",
    "        \n",
    "        Args:\n",
    "            logits (torch.Tensor): Logits from Wav2Vec2 model (T, V), where\n",
    "                T - number of time steps and\n",
    "                V - vocabulary size\n",
    "        \n",
    "        Returns:\n",
    "            str: Decoded transcript\n",
    "        \"\"\"\n",
    "        if not self.lm_model:\n",
    "            raise ValueError(\"KenLM model required for LM shallow fusion\")\n",
    "        log_probs = torch.log_softmax(logits, dim=-1)\n",
    "        current_beam = {(): (0.0, \"\")}\n",
    "        for t in range(log_probs.shape[0]):\n",
    "            new_beam = {}\n",
    "            for hypothesis, (score, text) in current_beam.items():\n",
    "                blank_score = score + log_probs[t, self.blank_token_id].item()            \n",
    "                if hypothesis in new_beam:\n",
    "                    if blank_score > new_beam[hypothesis][0]:\n",
    "                        new_beam[hypothesis] = (blank_score, text)\n",
    "                else:\n",
    "                    new_beam[hypothesis] = (blank_score, text)\n",
    "                for token_id in range(log_probs.shape[1]):\n",
    "                    if token_id == self.blank_token_id:\n",
    "                        continue\n",
    "                    acoustic_score = log_probs[t, token_id].item()\n",
    "                    token_char = self.vocab[token_id]\n",
    "                    is_word_boundary = (token_char == self.word_delimiter)\n",
    "                    if len(hypothesis) > 0 and token_id == hypothesis[-1]:\n",
    "                        new_hypothesis = hypothesis\n",
    "                        new_text = text\n",
    "                    else:\n",
    "                        new_hypothesis = hypothesis + (token_id,)\n",
    "                        if token_char == self.word_delimiter:\n",
    "                            token_char = ' '\n",
    "                        new_text = text + token_char\n",
    "                    lm_score = 0.0\n",
    "                    if is_word_boundary or t == log_probs.shape[0] - 1:\n",
    "                        lm_score = self.lm_model.score(new_text, bos=True, eos=False) * 2.302585 #это для приведения к единой шкале логарифмов\n",
    "                    combined_score = score + acoustic_score + self.alpha * lm_score\n",
    "                    if is_word_boundary:\n",
    "                        combined_score += self.beta\n",
    "                    if new_hypothesis in new_beam:\n",
    "                        if combined_score > new_beam[new_hypothesis][0]:\n",
    "                            new_beam[new_hypothesis] = (combined_score, new_text)\n",
    "                    else:\n",
    "                        new_beam[new_hypothesis] = (combined_score, new_text)\n",
    "            sorted_beam = sorted(new_beam.items(), key=lambda x: x[1][0], reverse=True)\n",
    "            current_beam = dict(sorted_beam[:self.beam_width])\n",
    "        best_score = float('-inf')\n",
    "        best_transcript = \"\"    \n",
    "        for hypothesis, (score, text) in current_beam.items():\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_transcript = text  \n",
    "        return best_transcript.strip()\n",
    "\n",
    "    def lm_rescore(self, beams: List[Tuple[List[int], float]]) -> str:\n",
    "        \"\"\"\n",
    "        Perform second-pass LM rescoring on beam search outputs\n",
    "        \n",
    "        Args:\n",
    "            beams (list): List of tuples (hypothesis, log_prob)\n",
    "        \n",
    "        Returns:\n",
    "            str: Best rescored transcript\n",
    "        \"\"\"\n",
    "        if not self.lm_model:\n",
    "            raise ValueError(\"KenLM model required for LM rescoring\")\n",
    "        \n",
    "        best_score = float('-inf')\n",
    "        best_transcript = \"\"\n",
    "        for hypothesis, acoustic_score in beams:\n",
    "            text = ''.join([self.vocab[token] for token in hypothesis])\n",
    "            text = text.replace(self.word_delimiter, ' ')\n",
    "            lm_score = self.lm_model.score(text, bos=True, eos=False) * 2.302585\n",
    "            combined_score = acoustic_score + self.alpha * lm_score\n",
    "            word_count = text.count(' ') + 1\n",
    "            combined_score += self.beta * word_count\n",
    "            if combined_score > best_score:\n",
    "                best_score = combined_score\n",
    "                best_transcript = text\n",
    "        \n",
    "        return best_transcript.strip()\n",
    "\n",
    "    def decode(self, audio_input: torch.Tensor, method: str = \"greedy\") -> str:\n",
    "        \"\"\"\n",
    "        Decode input audio file using the specified method\n",
    "        \n",
    "        Args:\n",
    "            audio_input (torch.Tensor): Audio tensor\n",
    "            method (str): Decoding method (\"greedy\", \"beam\", \"beam_lm\", \"beam_lm_rescore\"),\n",
    "                where \"greedy\" is a greedy decoding,\n",
    "                      \"beam\" is beam search without LM,\n",
    "                      \"beam_lm\" is beam search with LM shallow fusion, and \n",
    "                      \"beam_lm_rescore\" is a beam search with second pass LM rescoring\n",
    "        \n",
    "        Returns:\n",
    "            str: Decoded transcription\n",
    "        \"\"\"\n",
    "        inputs = self.processor(audio_input, return_tensors=\"pt\", sampling_rate=16000)\n",
    "        with torch.no_grad():\n",
    "            logits = self.model(inputs.input_values.squeeze(0)).logits[0]\n",
    "\n",
    "        if method == \"greedy\":\n",
    "            return self.greedy_decode(logits)\n",
    "        elif method == \"beam\":\n",
    "            return self.beam_search_decode(logits)\n",
    "        elif method == \"beam_lm\":\n",
    "            return self.beam_search_with_lm(logits)\n",
    "        elif method == \"beam_lm_rescore\":\n",
    "            beams = self.beam_search_decode(logits, return_beams=True)\n",
    "            return self.lm_rescore(beams)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid decoding method. Choose one of 'greedy', 'beam', 'beam_lm', 'beam_lm_rescore'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d99aba6-c157-41b6-9288-40db507a2ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading /home/stas/workspace/courses/itmo_courses/sound/anton/hw2/lm/3-gram.pruned.1e-7.arpa.gz\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Target transcription\n",
      "IF YOU ARE GENEROUS HERE IS A FITTING OPPORTUNITY FOR THE EXERCISE OF YOUR MAGNANIMITY IF YOU ARE PROUD HERE AM I YOUR RIVAL READY TO ACKNOWLEDGE MYSELF YOUR DEBTOR FOR AN ACT OF THE MOST NOBLE FORBEARANCE\n",
      "------------------------------------------------------------\n",
      "greedy decoding\n",
      "IF YOU ARE GENEROUS HERE IS A FITTING OPPORTUNITY FOR THE EXERCISE OF YOUR MAGNANIMITY IF YOU ARE PROUD HERE AM I YOUR RIVAL RETER TO ACKNOWLEDGE MYSELF YOUR DEPTOR FOR AN ACT OF MOST NOBLE FORBEARANCE \n",
      "Character-level Levenshtein distance: 8\n",
      "------------------------------------------------------------\n",
      "beam decoding\n",
      "IF YOU ARE GENEROUS HERE IS A FITING OPORTUNITY FOR THE EXERCISE OF YOUR MAGNANIMITY IF YOU ARE PROUD HERE AM I YOUR RIVAL RETER TO ACKNOWLEDGE MYSELF YOUR DEPTOR FOR AN ACT OF MOST NOBLE FORBEARANCE \n",
      "Character-level Levenshtein distance: 10\n",
      "------------------------------------------------------------\n",
      "beam_lm decoding\n",
      "IF YOU ARE GENEROUS HERE IS A FITING OPORTUNITY FOR THE EXERCISE OF YOUR MAGNANIMITI IF YOU ARE PROUD HEREAM I YOURIVAL RETERTOACKNOWLEDGE MYSELF YOURDADEPTOR FOR AN ACT OF THE MOST NOBLEFORBEARANCE\n",
      "Character-level Levenshtein distance: 15\n",
      "------------------------------------------------------------\n",
      "beam_lm_rescore decoding\n",
      "IF YOU ARE GENEROUS HERE IS A FITING OPORTUNITY FOR THE EXERCISE OF YOUR MAGNANIMITY IF YOU ARE PROUD HERE AM I YOUR RIVAL RETER TO ACKNOWLEDGE MYSELF YOUR DEPTOR FOR AN ACT OF MOST NOBLE FORBEARRANCE\n",
      "Character-level Levenshtein distance: 11\n",
      "============================================================\n",
      "Target transcription\n",
      "AND IF ANY OF THE OTHER COPS HAD PRIVATE RACKETS OF THEIR OWN IZZY WAS UNDOUBTEDLY THE MAN TO FIND IT OUT AND USE THE INFORMATION WITH A BEAT SUCH AS THAT EVEN GOING HALVES AND WITH ALL THE GRAFT TO THE UPPER BRACKETS HE'D STILL BE ABLE TO MAKE HIS PILE IN A MATTER OF MONTHS\n",
      "------------------------------------------------------------\n",
      "greedy decoding\n",
      "AND IF ANY OF THE OTHER COPS HAD PRIVATE RACKETS OF THEIR OWN IZZY WAS UNDOUBTEDLY THE MAN TO FIND IT OUT AND USE THE INFORMATION WITH A BEAT SUCH AS THAT EVEN GOING HALVES AND WITH ALL THE GRAFT TO THE UPPER BRACKETS HE'D STILL BE ABLE TO MAKE HIS PILE IN A MATTER OF MONTHS \n",
      "Character-level Levenshtein distance: 0\n",
      "------------------------------------------------------------\n",
      "beam decoding\n",
      "AND IF ANY OF THE OTHER COPS HAD PRIVATE RACKETS OF THEIR OWN IZY WAS UNDOUBTEDLY THE MAN TO FIND IT OUT AND USE THE INFORMATION WITH A BEAT SUCH AS THAT EVEN GOING HALVES AND WITH AL THE GRAFT TO THE UPER BRACKETS HE'D STIL BE ABLE TO MAKE HIS PILE IN A MATER OF MONTHS \n",
      "Character-level Levenshtein distance: 5\n",
      "------------------------------------------------------------\n",
      "beam_lm decoding\n",
      "AND IF ANY OF THE OTHER COPS HAD PRIVATE RACKETS OF THEIR OWN IZY WAS UNDOUBTEDLY THE MAN TO FIND IT OUT AND USE THE INFORMATION WITHTABEATSUCH AS THATS EVEN NGOINGHALVES ANDWITHAL THETGRAFTO THE UPERBRACKETS HE'DSTIL BEABLETO MAKETHIS PILETINTAMATER OFAMONTHS\n",
      "Character-level Levenshtein distance: 25\n",
      "------------------------------------------------------------\n",
      "beam_lm_rescore decoding\n",
      "AND IF ANY OF THE OTHER COPS HAD PRIVATE RACKETS OF THEIR OWN IZY WAS UNDOUBTEDLY THE MAN TO FIND IT OUT AND USE THE INFORMATION WITH A BEAT SUCH AS THAT EVEN GOING HALVES AND WITH AL THE GRAFT TO THE UPER BRACKETS HE'D STIL BE ABLE TO MAKE HIS PILE IN A MATER OF MONTHS\n",
      "Character-level Levenshtein distance: 5\n",
      "============================================================\n",
      "Target transcription\n",
      "GUESS A MAN GETS USED TO ANYTHING HELL MAYBE I CAN HIRE SOME BUMS TO SIT AROUND AND WHOOP IT UP WHEN THE SHIPS COME IN AND BILL THIS AS A REAL OLD MARTIAN DEN OF SIN\n",
      "------------------------------------------------------------\n",
      "greedy decoding\n",
      "GUESS A MAN GETS USED TO ANYTHING HELL MAYBE I CAN HIRE SOME BUMS TO SIT AROUND AND WHOOP IT UP WHEN THE SHIPS COME IN AND BILL THIS IS A REAL OLD MARTIAN DEN OF SIN \n",
      "Character-level Levenshtein distance: 1\n",
      "------------------------------------------------------------\n",
      "beam decoding\n",
      "GUES A MAN GETS USED TO ANYTHING HEL MAYBE I CAN HIRE SOME BUMS TO SIT AROUND AND WHOP IT UP WHEN THE SHIPS COME IN AND BIL THIS IS A REAL OLD MARTIAN DEN OF SIN \n",
      "Character-level Levenshtein distance: 5\n",
      "------------------------------------------------------------\n",
      "beam_lm decoding\n",
      "GUES A MAN GETS USED TO ANYTHING HEL MAYBE I CAN HIRESOME BUMBS TO SIT AROUND AND WHOPIT UPWHEN THE SHIPS COME IN AND BILTHISIS A REALOLD MARTIANDENOFSIN\n",
      "Character-level Levenshtein distance: 15\n",
      "------------------------------------------------------------\n",
      "beam_lm_rescore decoding\n",
      "GUES A MAN GETS USED TO ANYTHING HEL MAYBE I CAN HIRE SOME BUMS TO SIT AROUND AND WHOP IT UP WHEN THE SHIPS COME IN AND BIL THIS IS A REAL OLD MARTIAN DEN OF SIN\n",
      "Character-level Levenshtein distance: 5\n",
      "============================================================\n",
      "Target transcription\n",
      "IT WAS A TUNE THEY HAD ALL HEARD HUNDREDS OF TIMES SO THERE WAS NO DIFFICULTY IN TURNING OUT A PASSABLE IMITATION OF IT TO THE IMPROVISED STRAINS OF I DIDN'T WANT TO DO IT THE PRISONER STRODE FORTH TO FREEDOM\n",
      "------------------------------------------------------------\n",
      "greedy decoding\n",
      "IT WAS TE TUNE THEY HAD ALL HEARD HUNDREDS OF TIMES SO THERE WAS NO DIFFICULTY IN TURNING OUT A PASSABLE IMITATION OF IT TO THE IMPROVISED TRAINS OF I DIDN'T WANT TO DO IT THE PRISONERS STRODE FORTH TO FREEDOM \n",
      "Character-level Levenshtein distance: 4\n",
      "------------------------------------------------------------\n",
      "beam decoding\n"
     ]
    }
   ],
   "source": [
    "def test(decoder, audio_path, true_transcription):\n",
    "\n",
    "    import Levenshtein\n",
    "\n",
    "    audio_input, sr = torchaudio.load(audio_path)\n",
    "    assert sr == 16000, \"Audio sample rate must be 16kHz\"\n",
    "\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Target transcription\")\n",
    "    print(true_transcription)\n",
    "\n",
    "    # Print all decoding methods results\n",
    "    for d_strategy in [\"greedy\", \"beam\", \"beam_lm\", \"beam_lm_rescore\"]:\n",
    "        print(\"-\" * 60)\n",
    "        print(f\"{d_strategy} decoding\") \n",
    "        transcript = decoder.decode(audio_input, method=d_strategy)\n",
    "        print(f\"{transcript}\")\n",
    "        print(f\"Character-level Levenshtein distance: {Levenshtein.distance(true_transcription, transcript.strip())}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    test_samples = [\n",
    "        (\"examples/sample1.wav\", \"IF YOU ARE GENEROUS HERE IS A FITTING OPPORTUNITY FOR THE EXERCISE OF YOUR MAGNANIMITY IF YOU ARE PROUD HERE AM I YOUR RIVAL READY TO ACKNOWLEDGE MYSELF YOUR DEBTOR FOR AN ACT OF THE MOST NOBLE FORBEARANCE\"),\n",
    "        (\"examples/sample2.wav\", \"AND IF ANY OF THE OTHER COPS HAD PRIVATE RACKETS OF THEIR OWN IZZY WAS UNDOUBTEDLY THE MAN TO FIND IT OUT AND USE THE INFORMATION WITH A BEAT SUCH AS THAT EVEN GOING HALVES AND WITH ALL THE GRAFT TO THE UPPER BRACKETS HE'D STILL BE ABLE TO MAKE HIS PILE IN A MATTER OF MONTHS\"),\n",
    "        (\"examples/sample3.wav\", \"GUESS A MAN GETS USED TO ANYTHING HELL MAYBE I CAN HIRE SOME BUMS TO SIT AROUND AND WHOOP IT UP WHEN THE SHIPS COME IN AND BILL THIS AS A REAL OLD MARTIAN DEN OF SIN\"),\n",
    "        (\"examples/sample4.wav\", \"IT WAS A TUNE THEY HAD ALL HEARD HUNDREDS OF TIMES SO THERE WAS NO DIFFICULTY IN TURNING OUT A PASSABLE IMITATION OF IT TO THE IMPROVISED STRAINS OF I DIDN'T WANT TO DO IT THE PRISONER STRODE FORTH TO FREEDOM\"),\n",
    "        (\"examples/sample5.wav\", \"MARGUERITE TIRED OUT WITH THIS LONG CONFESSION THREW HERSELF BACK ON THE SOFA AND TO STIFLE A SLIGHT COUGH PUT UP HER HANDKERCHIEF TO HER LIPS AND FROM THAT TO HER EYES\"),\n",
    "        (\"examples/sample6.wav\", \"AT THIS TIME ALL PARTICIPANTS ARE IN A LISTEN ONLY MODE\"),\n",
    "        (\"examples/sample7.wav\", \"THE INCREASE WAS MAINLY ATTRIBUTABLE TO THE NET INCREASE IN THE AVERAGE SIZE OF OUR FLEETS\"),\n",
    "        (\"examples/sample8.wav\", \"OPERATING SURPLUS IS A NON CAP FINANCIAL MEASURE WHICH IS DEFINED AS FULLY IN OUR PRESS RELEASE\"),\n",
    "    ]\n",
    "\n",
    "    decoder = Wav2Vec2Decoder()\n",
    "\n",
    "    _ = [test(decoder, audio_path, target) for audio_path, target in test_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eba1390-2e24-491f-a7c2-93e5b14a8890",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
